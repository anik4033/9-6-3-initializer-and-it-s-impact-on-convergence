{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d030e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e034a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2850, 60, 60, 3)\n",
      "(2850, 3)\n",
      "(150, 60, 60, 3)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"./data/train_x.pickle\",\"rb\")\n",
    "train_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/train_y.pickle\",\"rb\")\n",
    "train_y = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_x.pickle\",\"rb\")\n",
    "test_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_y.pickle\",\"rb\")\n",
    "test_y = pickle.load(pickle_in)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65048a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "n_input = 10800\n",
    "learning_rate = 0.001\n",
    "training_iters = 10\n",
    "batch_size = 512\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4a6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of placeholder (?, 60, 60, 3) (?, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size=60\n",
    "num_channels=3\n",
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels]) \n",
    "y_ = tf.compat.v1.placeholder(tf.float32, [None, num_classes])\n",
    "print('Shape of placeholder',x.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223a4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c9083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.normal([5, 5, 3, 32]),name='w1'),\n",
    "    'w2': tf.Variable(tf.random.normal([5, 5, 32, 64]),name='w2'),\n",
    "    'w3': tf.Variable(tf.random.normal([5, 5, 64, 128]),name='w3'),\n",
    "    'wd1': tf.Variable(tf.random.normal([8 * 8 * 128, 2048]),name='wd1'),  \n",
    "    'wout': tf.Variable(tf.random.normal([2048, num_classes]),name='wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([32]),name='b1'),\n",
    "    'b2': tf.Variable(tf.random.normal([64]),name='b2'),\n",
    "    'b3': tf.Variable(tf.random.normal([128]),name='b3'),\n",
    "    'bd1': tf.Variable(tf.random.normal([2048]),name='bd1'),\n",
    "    'bout': tf.Variable(tf.random.normal([num_classes]),name='bout')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be02cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):\n",
    "        \n",
    "    # reshape input to 60x60x3 size\n",
    "    x = tf.reshape(x, shape=[-1, 60, 60, 3])  \n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size of x is\")\n",
    "    print(x.shape)\n",
    "    \n",
    "  \n",
    "    conv1 = conv2d(x, weights['w1'], biases['b1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 1st conv layer is \")\n",
    "    print(conv1.shape)\n",
    "\n",
    "    \n",
    "    #input is 30*30*32 image\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['w2'], biases['b2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 2nd conv and pooling layer is\")\n",
    "    print(conv2.shape)\n",
    "    \n",
    "    \n",
    "    ### third conv layer\n",
    "    # input is 15*15*64 image\n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['w3'], biases['b3'])\n",
    "  \n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 3rd conv and pooling layer is\")\n",
    "    print(conv3.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #input is 8*8*128 \n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input   = 8*8*128 = 8192\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after flattening the image\")\n",
    "    print(fc1)  #8192 is the output\n",
    "    \n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after fully connected layer\")\n",
    "    print(fc1)\n",
    "    \n",
    "    \n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['wout']), biases['bout'])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"Output layer\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146f8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "size of x is\n",
      "(?, 60, 60, 3)\n",
      "----------------------------------------------------------------------------\n",
      "size after 1st conv layer is \n",
      "(?, 30, 30, 32)\n",
      "----------------------------------------------------------------------------\n",
      "size after 2nd conv and pooling layer is\n",
      "(?, 15, 15, 64)\n",
      "----------------------------------------------------------------------------\n",
      "size after 3rd conv and pooling layer is\n",
      "(?, 8, 8, 128)\n",
      "----------------------------------------------------------------------------\n",
      "shape after flattening the image\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 8192), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "shape after fully connected layer\n",
      "Tensor(\"Relu_3:0\", shape=(?, 2048), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "Output layer\n",
      "Tensor(\"Add_1:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = conv_net(x, weights, biases)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9bea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y_))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bede4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9a2a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  4312453.0\n",
      "epoch :  1  -  cost:  4400386.0\n",
      "epoch :  2  -  cost:  5290323.0\n",
      "epoch :  3  -  cost:  4702528.0\n",
      "epoch :  4  -  cost:  2932652.0\n",
      "epoch :  5  -  cost:  2252504.2\n",
      "epoch :  6  -  cost:  1554134.9\n",
      "epoch :  7  -  cost:  2601072.2\n",
      "epoch :  8  -  cost:  2489491.5\n",
      "epoch :  9  -  cost:  1365592.6\n",
      "epoch :  10  -  cost:  971081.94\n",
      "epoch :  11  -  cost:  1462924.2\n",
      "epoch :  12  -  cost:  1688363.6\n",
      "epoch :  13  -  cost:  1668195.8\n",
      "epoch :  14  -  cost:  1409376.2\n",
      "epoch :  15  -  cost:  958993.5\n",
      "epoch :  16  -  cost:  765100.4\n",
      "epoch :  17  -  cost:  1012586.2\n",
      "epoch :  18  -  cost:  1113777.4\n",
      "epoch :  19  -  cost:  937414.25\n",
      "epoch :  20  -  cost:  872413.94\n",
      "epoch :  21  -  cost:  866078.9\n",
      "epoch :  22  -  cost:  722928.7\n",
      "epoch :  23  -  cost:  658729.5\n",
      "epoch :  24  -  cost:  772838.5\n",
      "epoch :  25  -  cost:  825607.4\n",
      "epoch :  26  -  cost:  711903.5\n",
      "epoch :  27  -  cost:  565382.1\n",
      "epoch :  28  -  cost:  563027.5\n",
      "epoch :  29  -  cost:  657916.06\n",
      "epoch :  30  -  cost:  659782.8\n",
      "epoch :  31  -  cost:  581605.2\n",
      "epoch :  32  -  cost:  547015.1\n",
      "epoch :  33  -  cost:  522970.53\n",
      "epoch :  34  -  cost:  500242.94\n",
      "epoch :  35  -  cost:  516523.94\n",
      "epoch :  36  -  cost:  531579.9\n",
      "epoch :  37  -  cost:  492102.38\n",
      "epoch :  38  -  cost:  435180.16\n",
      "epoch :  39  -  cost:  438931.34\n",
      "epoch :  40  -  cost:  467909.3\n",
      "epoch :  41  -  cost:  447986.53\n",
      "epoch :  42  -  cost:  421011.34\n",
      "epoch :  43  -  cost:  411000.5\n",
      "epoch :  44  -  cost:  396014.72\n",
      "epoch :  45  -  cost:  398212.28\n",
      "epoch :  46  -  cost:  404519.56\n",
      "epoch :  47  -  cost:  383400.7\n",
      "epoch :  48  -  cost:  357062.88\n",
      "epoch :  49  -  cost:  361115.62\n",
      "epoch :  50  -  cost:  364048.53\n",
      "epoch :  51  -  cost:  347297.25\n",
      "epoch :  52  -  cost:  338886.2\n",
      "epoch :  53  -  cost:  327353.4\n",
      "epoch :  54  -  cost:  323245.22\n",
      "epoch :  55  -  cost:  326090.53\n",
      "epoch :  56  -  cost:  309382.25\n",
      "epoch :  57  -  cost:  301342.9\n",
      "epoch :  58  -  cost:  302019.1\n",
      "epoch :  59  -  cost:  293437.84\n",
      "epoch :  60  -  cost:  289336.22\n",
      "epoch :  61  -  cost:  276981.8\n",
      "epoch :  62  -  cost:  277063.25\n",
      "epoch :  63  -  cost:  273054.56\n",
      "epoch :  64  -  cost:  263979.2\n",
      "epoch :  65  -  cost:  258557.9\n",
      "epoch :  66  -  cost:  253766.73\n",
      "epoch :  67  -  cost:  251811.1\n",
      "epoch :  68  -  cost:  242589.02\n",
      "epoch :  69  -  cost:  239406.84\n",
      "epoch :  70  -  cost:  234786.5\n",
      "epoch :  71  -  cost:  230683.83\n",
      "epoch :  72  -  cost:  223855.05\n",
      "epoch :  73  -  cost:  220975.27\n",
      "epoch :  74  -  cost:  216786.86\n",
      "epoch :  75  -  cost:  212143.27\n",
      "epoch :  76  -  cost:  206723.05\n",
      "epoch :  77  -  cost:  204906.67\n",
      "epoch :  78  -  cost:  198934.7\n",
      "epoch :  79  -  cost:  195890.34\n",
      "epoch :  80  -  cost:  192202.69\n",
      "epoch :  81  -  cost:  188367.94\n",
      "epoch :  82  -  cost:  184514.75\n",
      "epoch :  83  -  cost:  181378.38\n",
      "epoch :  84  -  cost:  177622.6\n",
      "epoch :  85  -  cost:  173461.4\n",
      "epoch :  86  -  cost:  171279.31\n",
      "epoch :  87  -  cost:  166561.78\n",
      "epoch :  88  -  cost:  163812.03\n",
      "epoch :  89  -  cost:  161004.28\n",
      "epoch :  90  -  cost:  156665.45\n",
      "epoch :  91  -  cost:  154801.6\n",
      "epoch :  92  -  cost:  151713.44\n",
      "epoch :  93  -  cost:  147999.44\n",
      "epoch :  94  -  cost:  144653.52\n",
      "epoch :  95  -  cost:  142737.02\n",
      "epoch :  96  -  cost:  139588.2\n",
      "epoch :  97  -  cost:  136134.61\n",
      "epoch :  98  -  cost:  133067.52\n",
      "epoch :  99  -  cost:  130612.28\n",
      "epoch :  100  -  cost:  128330.35\n",
      "epoch :  101  -  cost:  126300.41\n",
      "epoch :  102  -  cost:  123252.08\n",
      "epoch :  103  -  cost:  120295.91\n",
      "epoch :  104  -  cost:  117531.48\n",
      "epoch :  105  -  cost:  115243.734\n",
      "epoch :  106  -  cost:  112738.945\n",
      "epoch :  107  -  cost:  111537.07\n",
      "epoch :  108  -  cost:  109977.805\n",
      "epoch :  109  -  cost:  108784.01\n",
      "epoch :  110  -  cost:  104807.77\n",
      "epoch :  111  -  cost:  100956.02\n",
      "epoch :  112  -  cost:  98210.03\n",
      "epoch :  113  -  cost:  97610.28\n",
      "epoch :  114  -  cost:  97572.5\n",
      "epoch :  115  -  cost:  96216.42\n",
      "epoch :  116  -  cost:  93414.96\n",
      "epoch :  117  -  cost:  90050.42\n",
      "epoch :  118  -  cost:  85884.43\n",
      "epoch :  119  -  cost:  83824.336\n",
      "epoch :  120  -  cost:  82721.7\n",
      "epoch :  121  -  cost:  81206.42\n",
      "epoch :  122  -  cost:  78898.38\n",
      "epoch :  123  -  cost:  76034.06\n",
      "epoch :  124  -  cost:  73838.75\n",
      "epoch :  125  -  cost:  72108.34\n",
      "epoch :  126  -  cost:  70760.55\n",
      "epoch :  127  -  cost:  71810.15\n",
      "epoch :  128  -  cost:  74334.33\n",
      "epoch :  129  -  cost:  80023.9\n",
      "epoch :  130  -  cost:  71305.586\n",
      "epoch :  131  -  cost:  65097.12\n",
      "epoch :  132  -  cost:  60878.855\n",
      "epoch :  133  -  cost:  60336.824\n",
      "epoch :  134  -  cost:  63357.293\n",
      "epoch :  135  -  cost:  65640.23\n",
      "epoch :  136  -  cost:  66066.336\n",
      "epoch :  137  -  cost:  56217.23\n",
      "epoch :  138  -  cost:  52784.18\n",
      "epoch :  139  -  cost:  54920.05\n",
      "epoch :  140  -  cost:  53068.035\n",
      "epoch :  141  -  cost:  50882.28\n",
      "epoch :  142  -  cost:  47811.71\n",
      "epoch :  143  -  cost:  49512.773\n",
      "epoch :  144  -  cost:  51880.78\n",
      "epoch :  145  -  cost:  49120.59\n",
      "epoch :  146  -  cost:  45238.63\n",
      "epoch :  147  -  cost:  42298.19\n",
      "epoch :  148  -  cost:  42886.12\n",
      "epoch :  149  -  cost:  41911.406\n",
      "epoch :  150  -  cost:  39049.562\n",
      "epoch :  151  -  cost:  39732.33\n",
      "epoch :  152  -  cost:  38683.977\n",
      "epoch :  153  -  cost:  36373.73\n",
      "epoch :  154  -  cost:  35478.457\n",
      "epoch :  155  -  cost:  36280.617\n",
      "epoch :  156  -  cost:  35848.004\n",
      "epoch :  157  -  cost:  35277.33\n",
      "epoch :  158  -  cost:  32571.031\n",
      "epoch :  159  -  cost:  30562.268\n",
      "epoch :  160  -  cost:  30045.967\n",
      "epoch :  161  -  cost:  29682.396\n",
      "epoch :  162  -  cost:  29167.928\n",
      "epoch :  163  -  cost:  28193.055\n",
      "epoch :  164  -  cost:  26943.29\n",
      "epoch :  165  -  cost:  25807.973\n",
      "epoch :  166  -  cost:  24957.648\n",
      "epoch :  167  -  cost:  24364.287\n",
      "epoch :  168  -  cost:  23867.697\n",
      "epoch :  169  -  cost:  23065.02\n",
      "epoch :  170  -  cost:  22515.043\n",
      "epoch :  171  -  cost:  21876.018\n",
      "epoch :  172  -  cost:  22811.129\n",
      "epoch :  173  -  cost:  29544.463\n",
      "epoch :  174  -  cost:  50388.316\n",
      "epoch :  175  -  cost:  58133.42\n",
      "epoch :  176  -  cost:  21974.701\n",
      "epoch :  177  -  cost:  27476.264\n",
      "epoch :  178  -  cost:  74843.72\n",
      "epoch :  179  -  cost:  44078.688\n",
      "epoch :  180  -  cost:  19771.416\n",
      "epoch :  181  -  cost:  47802.75\n",
      "epoch :  182  -  cost:  32451.08\n",
      "epoch :  183  -  cost:  22617.322\n",
      "epoch :  184  -  cost:  19829.1\n",
      "epoch :  185  -  cost:  25937.145\n",
      "epoch :  186  -  cost:  25933.408\n",
      "epoch :  187  -  cost:  15803.121\n",
      "epoch :  188  -  cost:  24516.168\n",
      "epoch :  189  -  cost:  20917.398\n",
      "epoch :  190  -  cost:  15385.714\n",
      "epoch :  191  -  cost:  20754.209\n",
      "epoch :  192  -  cost:  14949.836\n",
      "epoch :  193  -  cost:  18069.232\n",
      "epoch :  194  -  cost:  19552.71\n",
      "epoch :  195  -  cost:  13075.489\n",
      "epoch :  196  -  cost:  16128.379\n",
      "epoch :  197  -  cost:  12562.807\n",
      "epoch :  198  -  cost:  15646.033\n",
      "epoch :  199  -  cost:  12225.986\n",
      "epoch :  200  -  cost:  16054.234\n",
      "epoch :  201  -  cost:  14501.017\n",
      "epoch :  202  -  cost:  11490.066\n",
      "epoch :  203  -  cost:  11697.698\n",
      "epoch :  204  -  cost:  11800.325\n",
      "epoch :  205  -  cost:  10134.442\n",
      "epoch :  206  -  cost:  12962.4\n",
      "epoch :  207  -  cost:  10881.972\n",
      "epoch :  208  -  cost:  13085.277\n",
      "epoch :  209  -  cost:  15007.406\n",
      "epoch :  210  -  cost:  8563.652\n",
      "epoch :  211  -  cost:  14799.441\n",
      "epoch :  212  -  cost:  12398.661\n",
      "epoch :  213  -  cost:  8851.989\n",
      "epoch :  214  -  cost:  8822.518\n",
      "epoch :  215  -  cost:  10697.478\n",
      "epoch :  216  -  cost:  8751.094\n",
      "epoch :  217  -  cost:  12214.108\n",
      "epoch :  218  -  cost:  18544.523\n",
      "epoch :  219  -  cost:  7076.1826\n",
      "epoch :  220  -  cost:  27735.164\n",
      "epoch :  221  -  cost:  60008.95\n",
      "epoch :  222  -  cost:  6594.904\n",
      "epoch :  223  -  cost:  60397.453\n",
      "epoch :  224  -  cost:  43180.61\n",
      "epoch :  225  -  cost:  9737.6045\n",
      "epoch :  226  -  cost:  28647.215\n",
      "epoch :  227  -  cost:  10218.564\n",
      "epoch :  228  -  cost:  26875.158\n",
      "epoch :  229  -  cost:  30105.375\n",
      "epoch :  230  -  cost:  6754.3257\n",
      "epoch :  231  -  cost:  16933.777\n",
      "epoch :  232  -  cost:  6215.1123\n",
      "epoch :  233  -  cost:  21859.492\n",
      "epoch :  234  -  cost:  6930.1445\n",
      "epoch :  235  -  cost:  32522.691\n",
      "epoch :  236  -  cost:  25790.656\n",
      "epoch :  237  -  cost:  7863.023\n",
      "epoch :  238  -  cost:  14651.864\n",
      "epoch :  239  -  cost:  8416.955\n",
      "epoch :  240  -  cost:  6060.268\n",
      "epoch :  241  -  cost:  17966.902\n",
      "epoch :  242  -  cost:  8558.691\n",
      "epoch :  243  -  cost:  30676.443\n",
      "epoch :  244  -  cost:  13159.3545\n",
      "epoch :  245  -  cost:  29412.56\n",
      "epoch :  246  -  cost:  51393.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  247  -  cost:  7073.1797\n",
      "epoch :  248  -  cost:  21906.027\n",
      "epoch :  249  -  cost:  4186.034\n",
      "epoch :  250  -  cost:  8707.62\n",
      "epoch :  251  -  cost:  8050.029\n",
      "epoch :  252  -  cost:  4333.7637\n",
      "epoch :  253  -  cost:  7505.701\n",
      "epoch :  254  -  cost:  4708.512\n",
      "epoch :  255  -  cost:  3882.905\n",
      "epoch :  256  -  cost:  5511.8066\n",
      "epoch :  257  -  cost:  4238.807\n",
      "epoch :  258  -  cost:  3300.0757\n",
      "epoch :  259  -  cost:  3822.5771\n",
      "epoch :  260  -  cost:  4339.092\n",
      "epoch :  261  -  cost:  3487.0452\n",
      "epoch :  262  -  cost:  3136.2834\n",
      "epoch :  263  -  cost:  3364.602\n",
      "epoch :  264  -  cost:  3028.36\n",
      "epoch :  265  -  cost:  2446.9958\n",
      "epoch :  266  -  cost:  2487.4277\n",
      "epoch :  267  -  cost:  2827.9358\n",
      "epoch :  268  -  cost:  2365.759\n",
      "epoch :  269  -  cost:  2109.4966\n",
      "epoch :  270  -  cost:  2117.5515\n",
      "epoch :  271  -  cost:  2092.5522\n",
      "epoch :  272  -  cost:  1925.0621\n",
      "epoch :  273  -  cost:  1938.1713\n",
      "epoch :  274  -  cost:  1997.9612\n",
      "epoch :  275  -  cost:  1774.6401\n",
      "epoch :  276  -  cost:  1627.0433\n",
      "epoch :  277  -  cost:  1633.3506\n",
      "epoch :  278  -  cost:  1542.2495\n",
      "epoch :  279  -  cost:  1387.8271\n",
      "epoch :  280  -  cost:  1358.1396\n",
      "epoch :  281  -  cost:  1376.0514\n",
      "epoch :  282  -  cost:  1350.1179\n",
      "epoch :  283  -  cost:  1268.4414\n",
      "epoch :  284  -  cost:  1203.813\n",
      "epoch :  285  -  cost:  1177.4928\n",
      "epoch :  286  -  cost:  1138.0012\n",
      "epoch :  287  -  cost:  1096.3942\n",
      "epoch :  288  -  cost:  1060.8524\n",
      "epoch :  289  -  cost:  1047.0822\n",
      "epoch :  290  -  cost:  1016.6307\n",
      "epoch :  291  -  cost:  974.9561\n",
      "epoch :  292  -  cost:  954.3419\n",
      "epoch :  293  -  cost:  929.18384\n",
      "epoch :  294  -  cost:  898.2298\n",
      "epoch :  295  -  cost:  866.694\n",
      "epoch :  296  -  cost:  837.5694\n",
      "epoch :  297  -  cost:  813.685\n",
      "epoch :  298  -  cost:  780.53033\n",
      "epoch :  299  -  cost:  754.0082\n",
      "epoch :  300  -  cost:  727.30853\n",
      "epoch :  301  -  cost:  704.27405\n",
      "epoch :  302  -  cost:  680.9704\n",
      "epoch :  303  -  cost:  663.17755\n",
      "epoch :  304  -  cost:  640.13873\n",
      "epoch :  305  -  cost:  621.6555\n",
      "epoch :  306  -  cost:  599.8187\n",
      "epoch :  307  -  cost:  574.23395\n",
      "epoch :  308  -  cost:  559.2541\n",
      "epoch :  309  -  cost:  532.59625\n",
      "epoch :  310  -  cost:  523.01685\n",
      "epoch :  311  -  cost:  502.41272\n",
      "epoch :  312  -  cost:  491.01004\n",
      "epoch :  313  -  cost:  456.38965\n",
      "epoch :  314  -  cost:  443.70776\n",
      "epoch :  315  -  cost:  452.17325\n",
      "epoch :  316  -  cost:  428.57385\n",
      "epoch :  317  -  cost:  387.94135\n",
      "epoch :  318  -  cost:  448.86838\n",
      "epoch :  319  -  cost:  360.61218\n",
      "epoch :  320  -  cost:  417.91434\n",
      "epoch :  321  -  cost:  332.53574\n",
      "epoch :  322  -  cost:  319.78635\n",
      "epoch :  323  -  cost:  340.0143\n",
      "epoch :  324  -  cost:  287.68338\n",
      "epoch :  325  -  cost:  275.06192\n",
      "epoch :  326  -  cost:  285.03424\n",
      "epoch :  327  -  cost:  244.43504\n",
      "epoch :  328  -  cost:  230.56447\n",
      "epoch :  329  -  cost:  221.81938\n",
      "epoch :  330  -  cost:  215.08653\n",
      "epoch :  331  -  cost:  200.40659\n",
      "epoch :  332  -  cost:  181.46237\n",
      "epoch :  333  -  cost:  162.96162\n",
      "epoch :  334  -  cost:  170.28421\n",
      "epoch :  335  -  cost:  143.1268\n",
      "epoch :  336  -  cost:  138.50175\n",
      "epoch :  337  -  cost:  133.19609\n",
      "epoch :  338  -  cost:  114.77816\n",
      "epoch :  339  -  cost:  97.49925\n",
      "epoch :  340  -  cost:  103.37776\n",
      "epoch :  341  -  cost:  90.67114\n",
      "epoch :  342  -  cost:  85.99303\n",
      "epoch :  343  -  cost:  91.109344\n",
      "epoch :  344  -  cost:  81.87399\n",
      "epoch :  345  -  cost:  73.1162\n",
      "epoch :  346  -  cost:  70.469345\n",
      "epoch :  347  -  cost:  66.056885\n",
      "epoch :  348  -  cost:  58.10307\n",
      "epoch :  349  -  cost:  58.317677\n",
      "epoch :  350  -  cost:  52.51215\n",
      "epoch :  351  -  cost:  44.74307\n",
      "epoch :  352  -  cost:  37.453617\n",
      "epoch :  353  -  cost:  42.49522\n",
      "epoch :  354  -  cost:  38.299824\n",
      "epoch :  355  -  cost:  49.5582\n",
      "epoch :  356  -  cost:  42.297894\n",
      "epoch :  357  -  cost:  22.469034\n",
      "epoch :  358  -  cost:  12.157062\n",
      "epoch :  359  -  cost:  24.883596\n",
      "epoch :  360  -  cost:  9.553728\n",
      "epoch :  361  -  cost:  13.84807\n",
      "epoch :  362  -  cost:  22.263247\n",
      "epoch :  363  -  cost:  2.5757017\n",
      "epoch :  364  -  cost:  0.0\n",
      "epoch :  365  -  cost:  17.790438\n",
      "epoch :  366  -  cost:  0.0\n",
      "epoch :  367  -  cost:  0.0\n",
      "epoch :  368  -  cost:  0.0\n",
      "epoch :  369  -  cost:  8.587105\n",
      "epoch :  370  -  cost:  0.0\n",
      "epoch :  371  -  cost:  0.0\n",
      "epoch :  372  -  cost:  0.8835965\n",
      "epoch :  373  -  cost:  8.115044\n",
      "epoch :  374  -  cost:  0.0\n",
      "epoch :  375  -  cost:  0.0\n",
      "epoch :  376  -  cost:  0.14157894\n",
      "epoch :  377  -  cost:  0.0\n",
      "epoch :  378  -  cost:  0.46570176\n",
      "epoch :  379  -  cost:  0.0\n",
      "epoch :  380  -  cost:  0.0\n",
      "epoch :  381  -  cost:  0.0\n",
      "epoch :  382  -  cost:  0.0\n",
      "epoch :  383  -  cost:  0.0\n",
      "epoch :  384  -  cost:  0.0\n",
      "epoch :  385  -  cost:  0.0\n",
      "epoch :  386  -  cost:  0.0\n",
      "epoch :  387  -  cost:  0.07333333\n",
      "epoch :  388  -  cost:  0.0\n",
      "epoch :  389  -  cost:  0.0\n",
      "epoch :  390  -  cost:  0.0\n",
      "epoch :  391  -  cost:  0.0\n",
      "epoch :  392  -  cost:  0.0\n",
      "epoch :  393  -  cost:  0.0\n",
      "epoch :  394  -  cost:  0.0\n",
      "epoch :  395  -  cost:  0.0\n",
      "epoch :  396  -  cost:  0.0\n",
      "epoch :  397  -  cost:  0.0\n",
      "epoch :  398  -  cost:  0.0\n",
      "epoch :  399  -  cost:  0.0\n",
      "epoch :  400  -  cost:  0.0\n",
      "epoch :  401  -  cost:  0.0\n",
      "epoch :  402  -  cost:  0.0\n",
      "epoch :  403  -  cost:  0.0\n",
      "epoch :  404  -  cost:  0.0\n",
      "epoch :  405  -  cost:  0.0\n",
      "epoch :  406  -  cost:  0.0\n",
      "epoch :  407  -  cost:  0.0\n",
      "epoch :  408  -  cost:  0.0\n",
      "epoch :  409  -  cost:  0.0\n",
      "epoch :  410  -  cost:  0.0\n",
      "epoch :  411  -  cost:  0.0\n",
      "epoch :  412  -  cost:  0.0\n",
      "epoch :  413  -  cost:  0.0\n",
      "epoch :  414  -  cost:  0.0\n",
      "epoch :  415  -  cost:  0.0\n",
      "epoch :  416  -  cost:  0.0\n",
      "epoch :  417  -  cost:  0.0\n",
      "epoch :  418  -  cost:  0.0\n",
      "epoch :  419  -  cost:  0.0\n",
      "epoch :  420  -  cost:  0.0\n",
      "epoch :  421  -  cost:  0.0\n",
      "epoch :  422  -  cost:  0.0\n",
      "epoch :  423  -  cost:  0.0\n",
      "epoch :  424  -  cost:  0.0\n",
      "epoch :  425  -  cost:  0.0\n",
      "epoch :  426  -  cost:  0.0\n",
      "epoch :  427  -  cost:  0.0\n",
      "epoch :  428  -  cost:  0.0\n",
      "epoch :  429  -  cost:  0.0\n",
      "epoch :  430  -  cost:  0.0\n",
      "epoch :  431  -  cost:  0.0\n",
      "epoch :  432  -  cost:  0.0\n",
      "epoch :  433  -  cost:  0.0\n",
      "epoch :  434  -  cost:  0.0\n",
      "epoch :  435  -  cost:  0.0\n",
      "epoch :  436  -  cost:  0.0\n",
      "epoch :  437  -  cost:  0.0\n",
      "epoch :  438  -  cost:  0.0\n",
      "epoch :  439  -  cost:  0.0\n",
      "epoch :  440  -  cost:  0.0\n",
      "epoch :  441  -  cost:  0.0\n",
      "epoch :  442  -  cost:  0.0\n",
      "epoch :  443  -  cost:  0.0\n",
      "epoch :  444  -  cost:  0.0\n",
      "epoch :  445  -  cost:  0.0\n",
      "epoch :  446  -  cost:  0.0\n",
      "epoch :  447  -  cost:  0.0\n",
      "epoch :  448  -  cost:  0.0\n",
      "epoch :  449  -  cost:  0.0\n",
      "epoch :  450  -  cost:  0.0\n",
      "epoch :  451  -  cost:  0.0\n",
      "epoch :  452  -  cost:  0.0\n",
      "epoch :  453  -  cost:  0.0\n",
      "epoch :  454  -  cost:  0.0\n",
      "epoch :  455  -  cost:  0.0\n",
      "epoch :  456  -  cost:  0.0\n",
      "epoch :  457  -  cost:  0.0\n",
      "epoch :  458  -  cost:  0.0\n",
      "epoch :  459  -  cost:  0.0\n",
      "epoch :  460  -  cost:  0.0\n",
      "epoch :  461  -  cost:  0.0\n",
      "epoch :  462  -  cost:  0.0\n",
      "epoch :  463  -  cost:  0.0\n",
      "epoch :  464  -  cost:  0.0\n",
      "epoch :  465  -  cost:  0.0\n",
      "epoch :  466  -  cost:  0.0\n",
      "epoch :  467  -  cost:  0.0\n",
      "epoch :  468  -  cost:  0.0\n",
      "epoch :  469  -  cost:  0.0\n",
      "epoch :  470  -  cost:  0.0\n",
      "epoch :  471  -  cost:  0.0\n",
      "epoch :  472  -  cost:  0.0\n",
      "epoch :  473  -  cost:  0.0\n",
      "epoch :  474  -  cost:  0.0\n",
      "epoch :  475  -  cost:  0.0\n",
      "epoch :  476  -  cost:  0.0\n",
      "epoch :  477  -  cost:  0.0\n",
      "epoch :  478  -  cost:  0.0\n",
      "epoch :  479  -  cost:  0.0\n",
      "epoch :  480  -  cost:  0.0\n",
      "epoch :  481  -  cost:  0.0\n",
      "epoch :  482  -  cost:  0.0\n",
      "epoch :  483  -  cost:  0.0\n",
      "epoch :  484  -  cost:  0.0\n",
      "epoch :  485  -  cost:  0.0\n",
      "epoch :  486  -  cost:  0.0\n",
      "epoch :  487  -  cost:  0.0\n",
      "epoch :  488  -  cost:  0.0\n",
      "epoch :  489  -  cost:  0.0\n",
      "epoch :  490  -  cost:  0.0\n",
      "epoch :  491  -  cost:  0.0\n",
      "epoch :  492  -  cost:  0.0\n",
      "epoch :  493  -  cost:  0.0\n",
      "epoch :  494  -  cost:  0.0\n",
      "epoch :  495  -  cost:  0.0\n",
      "epoch :  496  -  cost:  0.0\n",
      "epoch :  497  -  cost:  0.0\n",
      "epoch :  498  -  cost:  0.0\n",
      "epoch :  499  -  cost:  0.0\n"
     ]
    }
   ],
   "source": [
    "cost_history=[]\n",
    "n_epochs =500\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(init)\n",
    "train_y=train_y.todense()\n",
    "for i in range(n_epochs):\n",
    "    a, c = sess.run([optimizer, cost], feed_dict={x: train_x, y_: train_y})  \n",
    "    cost_history = np.append(cost_history,c)  \n",
    "    print('epoch : ', i, ' - ', 'cost: ', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5650acf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(range(0,500), cost_history[0:500])\n",
    "plt.ylabel('COST')\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylim([0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f56cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.64666665\n"
     ]
    }
   ],
   "source": [
    "test_y=test_y.todense() \n",
    "correct_prediction = tf.equal(tf.argmax(model,1), tf.argmax(y_,1))   \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={x: test_x, y_:test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619270a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1] *",
   "language": "python",
   "name": "conda-env-tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
