{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d030e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6679900",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e034a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2850, 60, 60, 3)\n",
      "(2850, 3)\n",
      "(150, 60, 60, 3)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"./data/train_x.pickle\",\"rb\")\n",
    "train_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/train_y.pickle\",\"rb\")\n",
    "train_y = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_x.pickle\",\"rb\")\n",
    "test_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_y.pickle\",\"rb\")\n",
    "test_y = pickle.load(pickle_in)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65048a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "n_input = 10800\n",
    "learning_rate = 0.001\n",
    "training_iters = 10\n",
    "batch_size = 128\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4a6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of placeholder (?, 60, 60, 3) (?, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size=60\n",
    "num_channels=3\n",
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels]) \n",
    "y_ = tf.compat.v1.placeholder(tf.float32, [None, num_classes])\n",
    "print('Shape of placeholder',x.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223a4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c9083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.normal([5, 5, 3, 32])/np.sqrt(9),name='w1'),\n",
    "    'w2': tf.Variable(tf.random.normal([5, 5, 32, 64])/(np.sqrt(6)),name='w2'),\n",
    "    'w3': tf.Variable(tf.random.normal([5, 5, 64, 128])/(np.sqrt(3)),name='w3'),\n",
    "    'wd1': tf.Variable(tf.random.normal([8 * 8 * 128, 2048]),name='wd1'),  \n",
    "    'wout': tf.Variable(tf.random.normal([2048, num_classes]),name='wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([32])/np.sqrt(9),name='b1'),\n",
    "    'b2': tf.Variable(tf.random.normal([64])/np.sqrt(6),name='b2'),\n",
    "    'b3': tf.Variable(tf.random.normal([128])/np.sqrt(3),name='b3'),\n",
    "    'bd1': tf.Variable(tf.random.normal([2048]),name='bd1'),\n",
    "    'bout': tf.Variable(tf.random.normal([num_classes]),name='bout')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be02cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):\n",
    "        \n",
    "    # reshape input to 60x60x3 size\n",
    "    x = tf.reshape(x, shape=[-1, 60, 60, 3])  \n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size of x is\")\n",
    "    print(x.shape)\n",
    "    \n",
    "  \n",
    "    conv1 = conv2d(x, weights['w1'], biases['b1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 1st conv layer is \")\n",
    "    print(conv1.shape)\n",
    "\n",
    "    \n",
    "    #input is 30*30*32 image\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['w2'], biases['b2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 2nd conv and pooling layer is\")\n",
    "    print(conv2.shape)\n",
    "    \n",
    "    \n",
    "    ### third conv layer\n",
    "    # input is 15*15*64 image\n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['w3'], biases['b3'])\n",
    "  \n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 3rd conv and pooling layer is\")\n",
    "    print(conv3.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #input is 8*8*128 \n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input   = 8*8*128 = 8192\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after flattening the image\")\n",
    "    print(fc1)  #8192 is the output\n",
    "    \n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after fully connected layer\")\n",
    "    print(fc1)\n",
    "    \n",
    "    \n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['wout']), biases['bout'])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"Output layer\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146f8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "size of x is\n",
      "(?, 60, 60, 3)\n",
      "----------------------------------------------------------------------------\n",
      "size after 1st conv layer is \n",
      "(?, 30, 30, 32)\n",
      "----------------------------------------------------------------------------\n",
      "size after 2nd conv and pooling layer is\n",
      "(?, 15, 15, 64)\n",
      "----------------------------------------------------------------------------\n",
      "size after 3rd conv and pooling layer is\n",
      "(?, 8, 8, 128)\n",
      "----------------------------------------------------------------------------\n",
      "shape after flattening the image\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 8192), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "shape after fully connected layer\n",
      "Tensor(\"Relu_3:0\", shape=(?, 2048), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "Output layer\n",
      "Tensor(\"Add_1:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = conv_net(x, weights, biases)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9bea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y_))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bede4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9a2a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  443968.1\n",
      "epoch :  1  -  cost:  242030.12\n",
      "epoch :  2  -  cost:  367415.2\n",
      "epoch :  3  -  cost:  331444.7\n",
      "epoch :  4  -  cost:  188861.7\n",
      "epoch :  5  -  cost:  138586.08\n",
      "epoch :  6  -  cost:  123127.87\n",
      "epoch :  7  -  cost:  164584.4\n",
      "epoch :  8  -  cost:  178141.98\n",
      "epoch :  9  -  cost:  130726.01\n",
      "epoch :  10  -  cost:  64965.2\n",
      "epoch :  11  -  cost:  71025.555\n",
      "epoch :  12  -  cost:  101971.42\n",
      "epoch :  13  -  cost:  109075.02\n",
      "epoch :  14  -  cost:  97878.81\n",
      "epoch :  15  -  cost:  79410.664\n",
      "epoch :  16  -  cost:  59916.883\n",
      "epoch :  17  -  cost:  51922.08\n",
      "epoch :  18  -  cost:  59569.25\n",
      "epoch :  19  -  cost:  64797.453\n",
      "epoch :  20  -  cost:  57046.457\n",
      "epoch :  21  -  cost:  42648.254\n",
      "epoch :  22  -  cost:  42948.164\n",
      "epoch :  23  -  cost:  50662.113\n",
      "epoch :  24  -  cost:  47051.656\n",
      "epoch :  25  -  cost:  36564.27\n",
      "epoch :  26  -  cost:  31775.908\n",
      "epoch :  27  -  cost:  36320.832\n",
      "epoch :  28  -  cost:  40524.176\n",
      "epoch :  29  -  cost:  38473.285\n",
      "epoch :  30  -  cost:  31757.209\n",
      "epoch :  31  -  cost:  26334.363\n",
      "epoch :  32  -  cost:  27529.28\n",
      "epoch :  33  -  cost:  31747.17\n",
      "epoch :  34  -  cost:  31272.36\n",
      "epoch :  35  -  cost:  26534.98\n",
      "epoch :  36  -  cost:  24021.096\n",
      "epoch :  37  -  cost:  24643.955\n",
      "epoch :  38  -  cost:  25329.453\n",
      "epoch :  39  -  cost:  24482.082\n",
      "epoch :  40  -  cost:  22859.316\n",
      "epoch :  41  -  cost:  21870.53\n",
      "epoch :  42  -  cost:  22015.05\n",
      "epoch :  43  -  cost:  21496.836\n",
      "epoch :  44  -  cost:  20011.23\n",
      "epoch :  45  -  cost:  19502.953\n",
      "epoch :  46  -  cost:  20156.264\n",
      "epoch :  47  -  cost:  19948.79\n",
      "epoch :  48  -  cost:  18434.604\n",
      "epoch :  49  -  cost:  17210.41\n",
      "epoch :  50  -  cost:  17370.367\n",
      "epoch :  51  -  cost:  17719.71\n",
      "epoch :  52  -  cost:  17024.996\n",
      "epoch :  53  -  cost:  15924.134\n",
      "epoch :  54  -  cost:  15518.779\n",
      "epoch :  55  -  cost:  15501.527\n",
      "epoch :  56  -  cost:  15184.411\n",
      "epoch :  57  -  cost:  14576.951\n",
      "epoch :  58  -  cost:  14189.929\n",
      "epoch :  59  -  cost:  13907.468\n",
      "epoch :  60  -  cost:  13372.8955\n",
      "epoch :  61  -  cost:  13046.423\n",
      "epoch :  62  -  cost:  12930.758\n",
      "epoch :  63  -  cost:  12510.725\n",
      "epoch :  64  -  cost:  11916.226\n",
      "epoch :  65  -  cost:  11689.722\n",
      "epoch :  66  -  cost:  11614.356\n",
      "epoch :  67  -  cost:  11146.545\n",
      "epoch :  68  -  cost:  10661.608\n",
      "epoch :  69  -  cost:  10536.58\n",
      "epoch :  70  -  cost:  10318.919\n",
      "epoch :  71  -  cost:  9914.082\n",
      "epoch :  72  -  cost:  9660.79\n",
      "epoch :  73  -  cost:  9405.001\n",
      "epoch :  74  -  cost:  9136.186\n",
      "epoch :  75  -  cost:  8933.285\n",
      "epoch :  76  -  cost:  8607.102\n",
      "epoch :  77  -  cost:  8348.635\n",
      "epoch :  78  -  cost:  8206.983\n",
      "epoch :  79  -  cost:  7905.4185\n",
      "epoch :  80  -  cost:  7632.877\n",
      "epoch :  81  -  cost:  7472.7026\n",
      "epoch :  82  -  cost:  7224.946\n",
      "epoch :  83  -  cost:  7008.558\n",
      "epoch :  84  -  cost:  6798.461\n",
      "epoch :  85  -  cost:  6622.542\n",
      "epoch :  86  -  cost:  6410.3823\n",
      "epoch :  87  -  cost:  6205.6997\n",
      "epoch :  88  -  cost:  6042.83\n",
      "epoch :  89  -  cost:  5837.593\n",
      "epoch :  90  -  cost:  5648.067\n",
      "epoch :  91  -  cost:  5478.969\n",
      "epoch :  92  -  cost:  5305.326\n",
      "epoch :  93  -  cost:  5139.496\n",
      "epoch :  94  -  cost:  4982.683\n",
      "epoch :  95  -  cost:  4820.148\n",
      "epoch :  96  -  cost:  4668.4146\n",
      "epoch :  97  -  cost:  4520.1177\n",
      "epoch :  98  -  cost:  4368.302\n",
      "epoch :  99  -  cost:  4233.064\n",
      "epoch :  100  -  cost:  4081.9006\n",
      "epoch :  101  -  cost:  3957.833\n",
      "epoch :  102  -  cost:  3822.5713\n",
      "epoch :  103  -  cost:  3702.7747\n",
      "epoch :  104  -  cost:  3577.1958\n",
      "epoch :  105  -  cost:  3461.7876\n",
      "epoch :  106  -  cost:  3346.4873\n",
      "epoch :  107  -  cost:  3236.4343\n",
      "epoch :  108  -  cost:  3127.1062\n",
      "epoch :  109  -  cost:  3039.0588\n",
      "epoch :  110  -  cost:  2936.9143\n",
      "epoch :  111  -  cost:  2832.2402\n",
      "epoch :  112  -  cost:  2724.3313\n",
      "epoch :  113  -  cost:  2645.1118\n",
      "epoch :  114  -  cost:  2545.4292\n",
      "epoch :  115  -  cost:  2467.785\n",
      "epoch :  116  -  cost:  2384.8682\n",
      "epoch :  117  -  cost:  2300.9504\n",
      "epoch :  118  -  cost:  2222.4287\n",
      "epoch :  119  -  cost:  2140.7227\n",
      "epoch :  120  -  cost:  2076.2224\n",
      "epoch :  121  -  cost:  1999.2218\n",
      "epoch :  122  -  cost:  1936.3821\n",
      "epoch :  123  -  cost:  1859.1333\n",
      "epoch :  124  -  cost:  1801.2686\n",
      "epoch :  125  -  cost:  1722.8784\n",
      "epoch :  126  -  cost:  1677.3994\n",
      "epoch :  127  -  cost:  1662.2639\n",
      "epoch :  128  -  cost:  1622.0691\n",
      "epoch :  129  -  cost:  1521.03\n",
      "epoch :  130  -  cost:  1433.3715\n",
      "epoch :  131  -  cost:  1397.0746\n",
      "epoch :  132  -  cost:  1357.9565\n",
      "epoch :  133  -  cost:  1277.6732\n",
      "epoch :  134  -  cost:  1267.953\n",
      "epoch :  135  -  cost:  1218.179\n",
      "epoch :  136  -  cost:  1137.8821\n",
      "epoch :  137  -  cost:  1126.9609\n",
      "epoch :  138  -  cost:  1045.5986\n",
      "epoch :  139  -  cost:  1019.9893\n",
      "epoch :  140  -  cost:  987.4023\n",
      "epoch :  141  -  cost:  926.81256\n",
      "epoch :  142  -  cost:  942.8662\n",
      "epoch :  143  -  cost:  890.9842\n",
      "epoch :  144  -  cost:  823.49976\n",
      "epoch :  145  -  cost:  827.0616\n",
      "epoch :  146  -  cost:  770.5891\n",
      "epoch :  147  -  cost:  770.71204\n",
      "epoch :  148  -  cost:  732.97406\n",
      "epoch :  149  -  cost:  687.9414\n",
      "epoch :  150  -  cost:  675.8581\n",
      "epoch :  151  -  cost:  630.2874\n",
      "epoch :  152  -  cost:  632.3317\n",
      "epoch :  153  -  cost:  572.63916\n",
      "epoch :  154  -  cost:  563.2757\n",
      "epoch :  155  -  cost:  519.55115\n",
      "epoch :  156  -  cost:  507.4575\n",
      "epoch :  157  -  cost:  467.08838\n",
      "epoch :  158  -  cost:  455.49786\n",
      "epoch :  159  -  cost:  418.46677\n",
      "epoch :  160  -  cost:  410.1153\n",
      "epoch :  161  -  cost:  386.85236\n",
      "epoch :  162  -  cost:  363.29922\n",
      "epoch :  163  -  cost:  349.3872\n",
      "epoch :  164  -  cost:  322.6043\n",
      "epoch :  165  -  cost:  314.28214\n",
      "epoch :  166  -  cost:  307.90347\n",
      "epoch :  167  -  cost:  292.62585\n",
      "epoch :  168  -  cost:  266.2983\n",
      "epoch :  169  -  cost:  259.22592\n",
      "epoch :  170  -  cost:  266.85068\n",
      "epoch :  171  -  cost:  229.02948\n",
      "epoch :  172  -  cost:  260.72977\n",
      "epoch :  173  -  cost:  279.2806\n",
      "epoch :  174  -  cost:  198.00967\n",
      "epoch :  175  -  cost:  283.61328\n",
      "epoch :  176  -  cost:  446.20306\n",
      "epoch :  177  -  cost:  203.25362\n",
      "epoch :  178  -  cost:  365.13803\n",
      "epoch :  179  -  cost:  607.82117\n",
      "epoch :  180  -  cost:  166.47144\n",
      "epoch :  181  -  cost:  545.0584\n",
      "epoch :  182  -  cost:  231.19994\n",
      "epoch :  183  -  cost:  597.9529\n",
      "epoch :  184  -  cost:  250.68646\n",
      "epoch :  185  -  cost:  636.0606\n",
      "epoch :  186  -  cost:  353.8519\n",
      "epoch :  187  -  cost:  626.44977\n",
      "epoch :  188  -  cost:  490.4394\n",
      "epoch :  189  -  cost:  491.15982\n",
      "epoch :  190  -  cost:  289.83926\n",
      "epoch :  191  -  cost:  865.9428\n",
      "epoch :  192  -  cost:  272.19623\n",
      "epoch :  193  -  cost:  1377.9725\n",
      "epoch :  194  -  cost:  232.96068\n",
      "epoch :  195  -  cost:  2133.8325\n",
      "epoch :  196  -  cost:  104.325264\n",
      "epoch :  197  -  cost:  2793.1528\n",
      "epoch :  198  -  cost:  149.58434\n",
      "epoch :  199  -  cost:  621.74493\n",
      "epoch :  200  -  cost:  695.9092\n",
      "epoch :  201  -  cost:  170.55428\n",
      "epoch :  202  -  cost:  1385.1099\n",
      "epoch :  203  -  cost:  101.183395\n",
      "epoch :  204  -  cost:  743.33826\n",
      "epoch :  205  -  cost:  252.6932\n",
      "epoch :  206  -  cost:  83.24125\n",
      "epoch :  207  -  cost:  484.22595\n",
      "epoch :  208  -  cost:  272.64093\n",
      "epoch :  209  -  cost:  80.565384\n",
      "epoch :  210  -  cost:  208.86134\n",
      "epoch :  211  -  cost:  224.5936\n",
      "epoch :  212  -  cost:  86.059296\n",
      "epoch :  213  -  cost:  99.86924\n",
      "epoch :  214  -  cost:  190.10136\n",
      "epoch :  215  -  cost:  87.767006\n",
      "epoch :  216  -  cost:  54.98266\n",
      "epoch :  217  -  cost:  65.01434\n",
      "epoch :  218  -  cost:  126.722435\n",
      "epoch :  219  -  cost:  84.9832\n",
      "epoch :  220  -  cost:  50.9112\n",
      "epoch :  221  -  cost:  42.104748\n",
      "epoch :  222  -  cost:  40.284344\n",
      "epoch :  223  -  cost:  46.15051\n",
      "epoch :  224  -  cost:  53.781567\n",
      "epoch :  225  -  cost:  40.863678\n",
      "epoch :  226  -  cost:  30.442865\n",
      "epoch :  227  -  cost:  28.104225\n",
      "epoch :  228  -  cost:  28.854567\n",
      "epoch :  229  -  cost:  30.681063\n",
      "epoch :  230  -  cost:  31.990784\n",
      "epoch :  231  -  cost:  29.546844\n",
      "epoch :  232  -  cost:  25.153465\n",
      "epoch :  233  -  cost:  21.426462\n",
      "epoch :  234  -  cost:  18.636805\n",
      "epoch :  235  -  cost:  16.733181\n",
      "epoch :  236  -  cost:  15.260536\n",
      "epoch :  237  -  cost:  13.710902\n",
      "epoch :  238  -  cost:  13.591382\n",
      "epoch :  239  -  cost:  13.049421\n",
      "epoch :  240  -  cost:  10.947559\n",
      "epoch :  241  -  cost:  9.78447\n",
      "epoch :  242  -  cost:  8.787817\n",
      "epoch :  243  -  cost:  7.7952247\n",
      "epoch :  244  -  cost:  7.0824876\n",
      "epoch :  245  -  cost:  6.301527\n",
      "epoch :  246  -  cost:  5.4656396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  247  -  cost:  5.3019047\n",
      "epoch :  248  -  cost:  5.024047\n",
      "epoch :  249  -  cost:  4.82273\n",
      "epoch :  250  -  cost:  4.623605\n",
      "epoch :  251  -  cost:  4.4022717\n",
      "epoch :  252  -  cost:  4.156752\n",
      "epoch :  253  -  cost:  3.9384124\n",
      "epoch :  254  -  cost:  3.672889\n",
      "epoch :  255  -  cost:  3.412498\n",
      "epoch :  256  -  cost:  3.176374\n",
      "epoch :  257  -  cost:  2.9431586\n",
      "epoch :  258  -  cost:  2.692637\n",
      "epoch :  259  -  cost:  2.434125\n",
      "epoch :  260  -  cost:  2.285407\n",
      "epoch :  261  -  cost:  1.9987308\n",
      "epoch :  262  -  cost:  1.7948033\n",
      "epoch :  263  -  cost:  1.5819346\n",
      "epoch :  264  -  cost:  1.3432579\n",
      "epoch :  265  -  cost:  1.0807408\n",
      "epoch :  266  -  cost:  0.8170875\n",
      "epoch :  267  -  cost:  0.56771314\n",
      "epoch :  268  -  cost:  0.27282315\n",
      "epoch :  269  -  cost:  0.034600556\n",
      "epoch :  270  -  cost:  0.0\n",
      "epoch :  271  -  cost:  0.0\n",
      "epoch :  272  -  cost:  0.0\n",
      "epoch :  273  -  cost:  0.0\n",
      "epoch :  274  -  cost:  0.0\n",
      "epoch :  275  -  cost:  0.0\n",
      "epoch :  276  -  cost:  0.0\n",
      "epoch :  277  -  cost:  0.0\n",
      "epoch :  278  -  cost:  0.0\n",
      "epoch :  279  -  cost:  0.0\n",
      "epoch :  280  -  cost:  0.0\n",
      "epoch :  281  -  cost:  0.0\n",
      "epoch :  282  -  cost:  0.0\n",
      "epoch :  283  -  cost:  0.0\n",
      "epoch :  284  -  cost:  0.0\n",
      "epoch :  285  -  cost:  0.0\n",
      "epoch :  286  -  cost:  0.0\n",
      "epoch :  287  -  cost:  0.0\n",
      "epoch :  288  -  cost:  0.0\n",
      "epoch :  289  -  cost:  0.0\n",
      "epoch :  290  -  cost:  0.0\n",
      "epoch :  291  -  cost:  0.0\n",
      "epoch :  292  -  cost:  0.0\n",
      "epoch :  293  -  cost:  0.0\n",
      "epoch :  294  -  cost:  0.0\n",
      "epoch :  295  -  cost:  0.0\n",
      "epoch :  296  -  cost:  0.0\n",
      "epoch :  297  -  cost:  0.0\n",
      "epoch :  298  -  cost:  0.0\n",
      "epoch :  299  -  cost:  0.0\n",
      "epoch :  300  -  cost:  0.0\n",
      "epoch :  301  -  cost:  0.0\n",
      "epoch :  302  -  cost:  0.0\n",
      "epoch :  303  -  cost:  0.0\n",
      "epoch :  304  -  cost:  0.0\n",
      "epoch :  305  -  cost:  0.0\n",
      "epoch :  306  -  cost:  0.0\n",
      "epoch :  307  -  cost:  0.0\n",
      "epoch :  308  -  cost:  0.0\n",
      "epoch :  309  -  cost:  0.0\n",
      "epoch :  310  -  cost:  0.0\n",
      "epoch :  311  -  cost:  0.0\n",
      "epoch :  312  -  cost:  0.0\n",
      "epoch :  313  -  cost:  0.0\n",
      "epoch :  314  -  cost:  0.0\n",
      "epoch :  315  -  cost:  0.0\n",
      "epoch :  316  -  cost:  0.0\n",
      "epoch :  317  -  cost:  0.0\n",
      "epoch :  318  -  cost:  0.0\n",
      "epoch :  319  -  cost:  0.0\n",
      "epoch :  320  -  cost:  0.0\n",
      "epoch :  321  -  cost:  0.0\n",
      "epoch :  322  -  cost:  0.0\n",
      "epoch :  323  -  cost:  0.0\n",
      "epoch :  324  -  cost:  0.0\n",
      "epoch :  325  -  cost:  0.0\n",
      "epoch :  326  -  cost:  0.0\n",
      "epoch :  327  -  cost:  0.0\n",
      "epoch :  328  -  cost:  0.0\n",
      "epoch :  329  -  cost:  0.0\n",
      "epoch :  330  -  cost:  0.0\n",
      "epoch :  331  -  cost:  0.0\n",
      "epoch :  332  -  cost:  0.0\n",
      "epoch :  333  -  cost:  0.0\n",
      "epoch :  334  -  cost:  0.0\n",
      "epoch :  335  -  cost:  0.0\n",
      "epoch :  336  -  cost:  0.0\n",
      "epoch :  337  -  cost:  0.0\n",
      "epoch :  338  -  cost:  0.0\n",
      "epoch :  339  -  cost:  0.0\n",
      "epoch :  340  -  cost:  0.0\n",
      "epoch :  341  -  cost:  0.0\n",
      "epoch :  342  -  cost:  0.0\n",
      "epoch :  343  -  cost:  0.0\n",
      "epoch :  344  -  cost:  0.0\n",
      "epoch :  345  -  cost:  0.0\n",
      "epoch :  346  -  cost:  0.0\n",
      "epoch :  347  -  cost:  0.0\n",
      "epoch :  348  -  cost:  0.0\n",
      "epoch :  349  -  cost:  0.0\n",
      "epoch :  350  -  cost:  0.0\n",
      "epoch :  351  -  cost:  0.0\n",
      "epoch :  352  -  cost:  0.0\n",
      "epoch :  353  -  cost:  0.0\n",
      "epoch :  354  -  cost:  0.0\n",
      "epoch :  355  -  cost:  0.0\n",
      "epoch :  356  -  cost:  0.0\n",
      "epoch :  357  -  cost:  0.0\n",
      "epoch :  358  -  cost:  0.0\n",
      "epoch :  359  -  cost:  0.0\n",
      "epoch :  360  -  cost:  0.0\n",
      "epoch :  361  -  cost:  0.0\n",
      "epoch :  362  -  cost:  0.0\n",
      "epoch :  363  -  cost:  0.0\n",
      "epoch :  364  -  cost:  0.0\n",
      "epoch :  365  -  cost:  0.0\n",
      "epoch :  366  -  cost:  0.0\n",
      "epoch :  367  -  cost:  0.0\n",
      "epoch :  368  -  cost:  0.0\n",
      "epoch :  369  -  cost:  0.0\n",
      "epoch :  370  -  cost:  0.0\n",
      "epoch :  371  -  cost:  0.0\n",
      "epoch :  372  -  cost:  0.0\n",
      "epoch :  373  -  cost:  0.0\n",
      "epoch :  374  -  cost:  0.0\n",
      "epoch :  375  -  cost:  0.0\n",
      "epoch :  376  -  cost:  0.0\n",
      "epoch :  377  -  cost:  0.0\n",
      "epoch :  378  -  cost:  0.0\n",
      "epoch :  379  -  cost:  0.0\n",
      "epoch :  380  -  cost:  0.0\n",
      "epoch :  381  -  cost:  0.0\n",
      "epoch :  382  -  cost:  0.0\n",
      "epoch :  383  -  cost:  0.0\n",
      "epoch :  384  -  cost:  0.0\n",
      "epoch :  385  -  cost:  0.0\n",
      "epoch :  386  -  cost:  0.0\n",
      "epoch :  387  -  cost:  0.0\n",
      "epoch :  388  -  cost:  0.0\n",
      "epoch :  389  -  cost:  0.0\n",
      "epoch :  390  -  cost:  0.0\n",
      "epoch :  391  -  cost:  0.0\n",
      "epoch :  392  -  cost:  0.0\n",
      "epoch :  393  -  cost:  0.0\n",
      "epoch :  394  -  cost:  0.0\n",
      "epoch :  395  -  cost:  0.0\n",
      "epoch :  396  -  cost:  0.0\n",
      "epoch :  397  -  cost:  0.0\n",
      "epoch :  398  -  cost:  0.0\n",
      "epoch :  399  -  cost:  0.0\n",
      "epoch :  400  -  cost:  0.0\n",
      "epoch :  401  -  cost:  0.0\n",
      "epoch :  402  -  cost:  0.0\n",
      "epoch :  403  -  cost:  0.0\n",
      "epoch :  404  -  cost:  0.0\n",
      "epoch :  405  -  cost:  0.0\n",
      "epoch :  406  -  cost:  0.0\n",
      "epoch :  407  -  cost:  0.0\n",
      "epoch :  408  -  cost:  0.0\n",
      "epoch :  409  -  cost:  0.0\n",
      "epoch :  410  -  cost:  0.0\n",
      "epoch :  411  -  cost:  0.0\n",
      "epoch :  412  -  cost:  0.0\n",
      "epoch :  413  -  cost:  0.0\n",
      "epoch :  414  -  cost:  0.0\n",
      "epoch :  415  -  cost:  0.0\n",
      "epoch :  416  -  cost:  0.0\n",
      "epoch :  417  -  cost:  0.0\n",
      "epoch :  418  -  cost:  0.0\n",
      "epoch :  419  -  cost:  0.0\n",
      "epoch :  420  -  cost:  0.0\n",
      "epoch :  421  -  cost:  0.0\n",
      "epoch :  422  -  cost:  0.0\n",
      "epoch :  423  -  cost:  0.0\n",
      "epoch :  424  -  cost:  0.0\n",
      "epoch :  425  -  cost:  0.0\n",
      "epoch :  426  -  cost:  0.0\n",
      "epoch :  427  -  cost:  0.0\n",
      "epoch :  428  -  cost:  0.0\n",
      "epoch :  429  -  cost:  0.0\n",
      "epoch :  430  -  cost:  0.0\n",
      "epoch :  431  -  cost:  0.0\n",
      "epoch :  432  -  cost:  0.0\n",
      "epoch :  433  -  cost:  0.0\n",
      "epoch :  434  -  cost:  0.0\n",
      "epoch :  435  -  cost:  0.0\n",
      "epoch :  436  -  cost:  0.0\n",
      "epoch :  437  -  cost:  0.0\n",
      "epoch :  438  -  cost:  0.0\n",
      "epoch :  439  -  cost:  0.0\n",
      "epoch :  440  -  cost:  0.0\n",
      "epoch :  441  -  cost:  0.0\n",
      "epoch :  442  -  cost:  0.0\n",
      "epoch :  443  -  cost:  0.0\n",
      "epoch :  444  -  cost:  0.0\n",
      "epoch :  445  -  cost:  0.0\n",
      "epoch :  446  -  cost:  0.0\n",
      "epoch :  447  -  cost:  0.0\n",
      "epoch :  448  -  cost:  0.0\n",
      "epoch :  449  -  cost:  0.0\n",
      "epoch :  450  -  cost:  0.0\n",
      "epoch :  451  -  cost:  0.0\n",
      "epoch :  452  -  cost:  0.0\n",
      "epoch :  453  -  cost:  0.0\n",
      "epoch :  454  -  cost:  0.0\n",
      "epoch :  455  -  cost:  0.0\n",
      "epoch :  456  -  cost:  0.0\n",
      "epoch :  457  -  cost:  0.0\n",
      "epoch :  458  -  cost:  0.0\n",
      "epoch :  459  -  cost:  0.0\n",
      "epoch :  460  -  cost:  0.0\n",
      "epoch :  461  -  cost:  0.0\n",
      "epoch :  462  -  cost:  0.0\n",
      "epoch :  463  -  cost:  0.0\n",
      "epoch :  464  -  cost:  0.0\n",
      "epoch :  465  -  cost:  0.0\n",
      "epoch :  466  -  cost:  0.0\n",
      "epoch :  467  -  cost:  0.0\n",
      "epoch :  468  -  cost:  0.0\n",
      "epoch :  469  -  cost:  0.0\n",
      "epoch :  470  -  cost:  0.0\n",
      "epoch :  471  -  cost:  0.0\n",
      "epoch :  472  -  cost:  0.0\n",
      "epoch :  473  -  cost:  0.0\n",
      "epoch :  474  -  cost:  0.0\n",
      "epoch :  475  -  cost:  0.0\n",
      "epoch :  476  -  cost:  0.0\n",
      "epoch :  477  -  cost:  0.0\n",
      "epoch :  478  -  cost:  0.0\n",
      "epoch :  479  -  cost:  0.0\n",
      "epoch :  480  -  cost:  0.0\n",
      "epoch :  481  -  cost:  0.0\n",
      "epoch :  482  -  cost:  0.0\n",
      "epoch :  483  -  cost:  0.0\n",
      "epoch :  484  -  cost:  0.0\n",
      "epoch :  485  -  cost:  0.0\n",
      "epoch :  486  -  cost:  0.0\n",
      "epoch :  487  -  cost:  0.0\n",
      "epoch :  488  -  cost:  0.0\n",
      "epoch :  489  -  cost:  0.0\n",
      "epoch :  490  -  cost:  0.0\n",
      "epoch :  491  -  cost:  0.0\n",
      "epoch :  492  -  cost:  0.0\n",
      "epoch :  493  -  cost:  0.0\n",
      "epoch :  494  -  cost:  0.0\n",
      "epoch :  495  -  cost:  0.0\n",
      "epoch :  496  -  cost:  0.0\n",
      "epoch :  497  -  cost:  0.0\n",
      "epoch :  498  -  cost:  0.0\n",
      "epoch :  499  -  cost:  0.0\n"
     ]
    }
   ],
   "source": [
    "cost_history=[]\n",
    "n_epochs =500\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(init)\n",
    "train_y=train_y.todense()\n",
    "for i in range(n_epochs):\n",
    "    a, c = sess.run([optimizer, cost], feed_dict={x: train_x, y_: train_y})  \n",
    "    cost_history = np.append(cost_history,c)  \n",
    "    print('epoch : ', i, ' - ', 'cost: ', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5650acf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(range(0,500), cost_history[0:500])\n",
    "plt.ylabel('COST')\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylim([0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6468a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666667\n"
     ]
    }
   ],
   "source": [
    "test_y=test_y.todense() \n",
    "correct_prediction = tf.equal(tf.argmax(model,1), tf.argmax(y_,1))   \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={x: test_x, y_:test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba63988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr tf2.4 py3.8",
   "language": "python",
   "name": "cvpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
