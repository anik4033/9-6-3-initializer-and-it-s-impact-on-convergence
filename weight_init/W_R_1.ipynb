{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d030e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e034a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2850, 60, 60, 3)\n",
      "(2850, 3)\n",
      "(150, 60, 60, 3)\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"./data/train_x.pickle\",\"rb\")\n",
    "train_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/train_y.pickle\",\"rb\")\n",
    "train_y = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_x.pickle\",\"rb\")\n",
    "test_x = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"./data/test_y.pickle\",\"rb\")\n",
    "test_y = pickle.load(pickle_in)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65048a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "n_input = 10800\n",
    "learning_rate = 0.001\n",
    "training_iters = 10\n",
    "batch_size = 512\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4a6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of placeholder (?, 60, 60, 3) (?, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size=60\n",
    "num_channels=3\n",
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, img_size,img_size,num_channels]) \n",
    "y_ = tf.compat.v1.placeholder(tf.float32, [None, num_classes])\n",
    "print('Shape of placeholder',x.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223a4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c9083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.normal([5, 5, 3, 32]),name='w1'),\n",
    "    'w2': tf.Variable(tf.random.normal([5, 5, 32, 64]),name='w2'),\n",
    "    'w3': tf.Variable(tf.random.normal([5, 5, 64, 128]),name='w3'),\n",
    "    'wd1': tf.Variable(tf.random.normal([8 * 8 * 128, 2048]),name='wd1'),  \n",
    "    'wout': tf.Variable(tf.random.normal([2048, num_classes]),name='wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random.normal([32]),name='b1'),\n",
    "    'b2': tf.Variable(tf.random.normal([64]),name='b2'),\n",
    "    'b3': tf.Variable(tf.random.normal([128]),name='b3'),\n",
    "    'bd1': tf.Variable(tf.random.normal([2048]),name='bd1'),\n",
    "    'bout': tf.Variable(tf.random.normal([num_classes]),name='bout')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be02cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):\n",
    "        \n",
    "    # reshape input to 60x60x3 size\n",
    "    x = tf.reshape(x, shape=[-1, 60, 60, 3])  \n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size of x is\")\n",
    "    print(x.shape)\n",
    "    \n",
    "  \n",
    "    conv1 = conv2d(x, weights['w1'], biases['b1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 1st conv layer is \")\n",
    "    print(conv1.shape)\n",
    "\n",
    "    \n",
    "    #input is 30*30*32 image\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['w2'], biases['b2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 2nd conv and pooling layer is\")\n",
    "    print(conv2.shape)\n",
    "    \n",
    "    \n",
    "    ### third conv layer\n",
    "    # input is 15*15*64 image\n",
    "    # Convolution Layer\n",
    "    conv3 = conv2d(conv2, weights['w3'], biases['b3'])\n",
    "  \n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"size after 3rd conv and pooling layer is\")\n",
    "    print(conv3.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #input is 8*8*128 \n",
    "    # Fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input   = 8*8*128 = 8192\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after flattening the image\")\n",
    "    print(fc1)  #8192 is the output\n",
    "    \n",
    "    \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"shape after fully connected layer\")\n",
    "    print(fc1)\n",
    "    \n",
    "    \n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['wout']), biases['bout'])\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(\"Output layer\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146f8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "size of x is\n",
      "(?, 60, 60, 3)\n",
      "----------------------------------------------------------------------------\n",
      "size after 1st conv layer is \n",
      "(?, 30, 30, 32)\n",
      "----------------------------------------------------------------------------\n",
      "size after 2nd conv and pooling layer is\n",
      "(?, 15, 15, 64)\n",
      "----------------------------------------------------------------------------\n",
      "size after 3rd conv and pooling layer is\n",
      "(?, 8, 8, 128)\n",
      "----------------------------------------------------------------------------\n",
      "shape after flattening the image\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 8192), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "shape after fully connected layer\n",
      "Tensor(\"Relu_3:0\", shape=(?, 2048), dtype=float32)\n",
      "----------------------------------------------------------------------------\n",
      "Output layer\n",
      "Tensor(\"Add_1:0\", shape=(?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = conv_net(x, weights, biases)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9bea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=y_))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bede4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9a2a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  3602055.5\n",
      "epoch :  1  -  cost:  5122448.5\n",
      "epoch :  2  -  cost:  7021091.5\n",
      "epoch :  3  -  cost:  5088025.0\n",
      "epoch :  4  -  cost:  3419329.8\n",
      "epoch :  5  -  cost:  1257321.2\n",
      "epoch :  6  -  cost:  3042830.0\n",
      "epoch :  7  -  cost:  3450990.0\n",
      "epoch :  8  -  cost:  2203374.5\n",
      "epoch :  9  -  cost:  1491649.8\n",
      "epoch :  10  -  cost:  1292867.8\n",
      "epoch :  11  -  cost:  2156316.5\n",
      "epoch :  12  -  cost:  2035353.0\n",
      "epoch :  13  -  cost:  1387670.8\n",
      "epoch :  14  -  cost:  1336619.2\n",
      "epoch :  15  -  cost:  1088824.6\n",
      "epoch :  16  -  cost:  1064410.5\n",
      "epoch :  17  -  cost:  1363689.9\n",
      "epoch :  18  -  cost:  1365464.1\n",
      "epoch :  19  -  cost:  1045937.7\n",
      "epoch :  20  -  cost:  766420.44\n",
      "epoch :  21  -  cost:  907247.8\n",
      "epoch :  22  -  cost:  1008896.6\n",
      "epoch :  23  -  cost:  915250.2\n",
      "epoch :  24  -  cost:  965764.4\n",
      "epoch :  25  -  cost:  831563.75\n",
      "epoch :  26  -  cost:  655872.7\n",
      "epoch :  27  -  cost:  713487.6\n",
      "epoch :  28  -  cost:  754052.4\n",
      "epoch :  29  -  cost:  726847.3\n",
      "epoch :  30  -  cost:  708249.44\n",
      "epoch :  31  -  cost:  648686.94\n",
      "epoch :  32  -  cost:  551116.75\n",
      "epoch :  33  -  cost:  574277.4\n",
      "epoch :  34  -  cost:  616328.0\n",
      "epoch :  35  -  cost:  567033.9\n",
      "epoch :  36  -  cost:  555181.5\n",
      "epoch :  37  -  cost:  499880.97\n",
      "epoch :  38  -  cost:  467486.3\n",
      "epoch :  39  -  cost:  504879.6\n",
      "epoch :  40  -  cost:  498560.8\n",
      "epoch :  41  -  cost:  459215.3\n",
      "epoch :  42  -  cost:  442669.4\n",
      "epoch :  43  -  cost:  420725.84\n",
      "epoch :  44  -  cost:  432115.6\n",
      "epoch :  45  -  cost:  434923.94\n",
      "epoch :  46  -  cost:  397411.34\n",
      "epoch :  47  -  cost:  390254.3\n",
      "epoch :  48  -  cost:  382214.06\n",
      "epoch :  49  -  cost:  383185.6\n",
      "epoch :  50  -  cost:  375973.16\n",
      "epoch :  51  -  cost:  347869.06\n",
      "epoch :  52  -  cost:  351824.97\n",
      "epoch :  53  -  cost:  345181.03\n",
      "epoch :  54  -  cost:  339732.3\n",
      "epoch :  55  -  cost:  325763.2\n",
      "epoch :  56  -  cost:  314610.56\n",
      "epoch :  57  -  cost:  318599.28\n",
      "epoch :  58  -  cost:  306193.38\n",
      "epoch :  59  -  cost:  300281.38\n",
      "epoch :  60  -  cost:  288409.34\n",
      "epoch :  61  -  cost:  292184.25\n",
      "epoch :  62  -  cost:  279081.7\n",
      "epoch :  63  -  cost:  274630.9\n",
      "epoch :  64  -  cost:  267301.34\n",
      "epoch :  65  -  cost:  267839.3\n",
      "epoch :  66  -  cost:  255741.94\n",
      "epoch :  67  -  cost:  254278.89\n",
      "epoch :  68  -  cost:  247688.44\n",
      "epoch :  69  -  cost:  244290.27\n",
      "epoch :  70  -  cost:  235924.75\n",
      "epoch :  71  -  cost:  233092.27\n",
      "epoch :  72  -  cost:  229425.0\n",
      "epoch :  73  -  cost:  222113.23\n",
      "epoch :  74  -  cost:  219800.56\n",
      "epoch :  75  -  cost:  215417.73\n",
      "epoch :  76  -  cost:  210116.27\n",
      "epoch :  77  -  cost:  206279.03\n",
      "epoch :  78  -  cost:  202769.83\n",
      "epoch :  79  -  cost:  198427.0\n",
      "epoch :  80  -  cost:  193865.45\n",
      "epoch :  81  -  cost:  191086.06\n",
      "epoch :  82  -  cost:  186255.06\n",
      "epoch :  83  -  cost:  182385.78\n",
      "epoch :  84  -  cost:  179695.23\n",
      "epoch :  85  -  cost:  174719.9\n",
      "epoch :  86  -  cost:  172315.19\n",
      "epoch :  87  -  cost:  169109.89\n",
      "epoch :  88  -  cost:  167010.72\n",
      "epoch :  89  -  cost:  165153.25\n",
      "epoch :  90  -  cost:  160414.4\n",
      "epoch :  91  -  cost:  156110.47\n",
      "epoch :  92  -  cost:  153168.86\n",
      "epoch :  93  -  cost:  149292.75\n",
      "epoch :  94  -  cost:  147327.67\n",
      "epoch :  95  -  cost:  144428.3\n",
      "epoch :  96  -  cost:  143828.6\n",
      "epoch :  97  -  cost:  144332.06\n",
      "epoch :  98  -  cost:  142000.19\n",
      "epoch :  99  -  cost:  135814.81\n",
      "epoch :  100  -  cost:  128583.76\n",
      "epoch :  101  -  cost:  126659.164\n",
      "epoch :  102  -  cost:  126675.04\n",
      "epoch :  103  -  cost:  126024.58\n",
      "epoch :  104  -  cost:  122989.92\n",
      "epoch :  105  -  cost:  116603.836\n",
      "epoch :  106  -  cost:  113069.586\n",
      "epoch :  107  -  cost:  111381.375\n",
      "epoch :  108  -  cost:  108931.52\n",
      "epoch :  109  -  cost:  105842.42\n",
      "epoch :  110  -  cost:  103799.68\n",
      "epoch :  111  -  cost:  101667.164\n",
      "epoch :  112  -  cost:  100955.4\n",
      "epoch :  113  -  cost:  99453.76\n",
      "epoch :  114  -  cost:  101737.91\n",
      "epoch :  115  -  cost:  106286.84\n",
      "epoch :  116  -  cost:  113812.7\n",
      "epoch :  117  -  cost:  101516.32\n",
      "epoch :  118  -  cost:  90359.15\n",
      "epoch :  119  -  cost:  85542.445\n",
      "epoch :  120  -  cost:  84853.74\n",
      "epoch :  121  -  cost:  86500.22\n",
      "epoch :  122  -  cost:  85133.195\n",
      "epoch :  123  -  cost:  82678.195\n",
      "epoch :  124  -  cost:  77822.45\n",
      "epoch :  125  -  cost:  75273.17\n",
      "epoch :  126  -  cost:  73008.734\n",
      "epoch :  127  -  cost:  71678.41\n",
      "epoch :  128  -  cost:  69832.0\n",
      "epoch :  129  -  cost:  69566.56\n",
      "epoch :  130  -  cost:  70106.15\n",
      "epoch :  131  -  cost:  73582.87\n",
      "epoch :  132  -  cost:  85835.84\n",
      "epoch :  133  -  cost:  90043.6\n",
      "epoch :  134  -  cost:  76351.78\n",
      "epoch :  135  -  cost:  64245.445\n",
      "epoch :  136  -  cost:  58747.44\n",
      "epoch :  137  -  cost:  59040.1\n",
      "epoch :  138  -  cost:  60904.87\n",
      "epoch :  139  -  cost:  62110.41\n",
      "epoch :  140  -  cost:  58287.81\n",
      "epoch :  141  -  cost:  54359.426\n",
      "epoch :  142  -  cost:  51736.824\n",
      "epoch :  143  -  cost:  51512.895\n",
      "epoch :  144  -  cost:  49965.17\n",
      "epoch :  145  -  cost:  48352.887\n",
      "epoch :  146  -  cost:  47279.516\n",
      "epoch :  147  -  cost:  47001.285\n",
      "epoch :  148  -  cost:  47104.223\n",
      "epoch :  149  -  cost:  47263.72\n",
      "epoch :  150  -  cost:  46598.027\n",
      "epoch :  151  -  cost:  49898.566\n",
      "epoch :  152  -  cost:  59441.773\n",
      "epoch :  153  -  cost:  74234.02\n",
      "epoch :  154  -  cost:  73387.47\n",
      "epoch :  155  -  cost:  53534.18\n",
      "epoch :  156  -  cost:  40775.164\n",
      "epoch :  157  -  cost:  38593.543\n",
      "epoch :  158  -  cost:  44861.86\n",
      "epoch :  159  -  cost:  42770.74\n",
      "epoch :  160  -  cost:  37897.25\n",
      "epoch :  161  -  cost:  35578.74\n",
      "epoch :  162  -  cost:  36460.1\n",
      "epoch :  163  -  cost:  33718.867\n",
      "epoch :  164  -  cost:  34166.457\n",
      "epoch :  165  -  cost:  32795.926\n",
      "epoch :  166  -  cost:  31591.436\n",
      "epoch :  167  -  cost:  32167.105\n",
      "epoch :  168  -  cost:  29581.543\n",
      "epoch :  169  -  cost:  31037.943\n",
      "epoch :  170  -  cost:  37206.96\n",
      "epoch :  171  -  cost:  37744.51\n",
      "epoch :  172  -  cost:  38212.074\n",
      "epoch :  173  -  cost:  31087.377\n",
      "epoch :  174  -  cost:  26909.625\n",
      "epoch :  175  -  cost:  26590.426\n",
      "epoch :  176  -  cost:  28579.096\n",
      "epoch :  177  -  cost:  27513.209\n",
      "epoch :  178  -  cost:  23809.707\n",
      "epoch :  179  -  cost:  25043.748\n",
      "epoch :  180  -  cost:  23607.668\n",
      "epoch :  181  -  cost:  22524.877\n",
      "epoch :  182  -  cost:  23412.8\n",
      "epoch :  183  -  cost:  21507.824\n",
      "epoch :  184  -  cost:  22062.426\n",
      "epoch :  185  -  cost:  24373.367\n",
      "epoch :  186  -  cost:  25122.986\n",
      "epoch :  187  -  cost:  22207.17\n",
      "epoch :  188  -  cost:  19036.9\n",
      "epoch :  189  -  cost:  21047.018\n",
      "epoch :  190  -  cost:  25318.234\n",
      "epoch :  191  -  cost:  39814.754\n",
      "epoch :  192  -  cost:  64337.87\n",
      "epoch :  193  -  cost:  59723.992\n",
      "epoch :  194  -  cost:  33177.32\n",
      "epoch :  195  -  cost:  20564.62\n",
      "epoch :  196  -  cost:  17644.455\n",
      "epoch :  197  -  cost:  19083.719\n",
      "epoch :  198  -  cost:  16574.13\n",
      "epoch :  199  -  cost:  18550.96\n",
      "epoch :  200  -  cost:  16639.764\n",
      "epoch :  201  -  cost:  17534.771\n",
      "epoch :  202  -  cost:  17891.05\n",
      "epoch :  203  -  cost:  14531.522\n",
      "epoch :  204  -  cost:  16448.76\n",
      "epoch :  205  -  cost:  14170.578\n",
      "epoch :  206  -  cost:  15552.135\n",
      "epoch :  207  -  cost:  15468.418\n",
      "epoch :  208  -  cost:  12823.618\n",
      "epoch :  209  -  cost:  14920.405\n",
      "epoch :  210  -  cost:  11988.648\n",
      "epoch :  211  -  cost:  13167.39\n",
      "epoch :  212  -  cost:  11843.759\n",
      "epoch :  213  -  cost:  11997.712\n",
      "epoch :  214  -  cost:  10877.583\n",
      "epoch :  215  -  cost:  12290.713\n",
      "epoch :  216  -  cost:  11779.065\n",
      "epoch :  217  -  cost:  11345.5\n",
      "epoch :  218  -  cost:  11504.76\n",
      "epoch :  219  -  cost:  12179.171\n",
      "epoch :  220  -  cost:  9824.168\n",
      "epoch :  221  -  cost:  9774.452\n",
      "epoch :  222  -  cost:  9755.818\n",
      "epoch :  223  -  cost:  9896.986\n",
      "epoch :  224  -  cost:  8505.337\n",
      "epoch :  225  -  cost:  9635.612\n",
      "epoch :  226  -  cost:  10427.027\n",
      "epoch :  227  -  cost:  7828.817\n",
      "epoch :  228  -  cost:  12119.778\n",
      "epoch :  229  -  cost:  32725.69\n",
      "epoch :  230  -  cost:  52487.06\n",
      "epoch :  231  -  cost:  44310.574\n",
      "epoch :  232  -  cost:  25136.115\n",
      "epoch :  233  -  cost:  11324.722\n",
      "epoch :  234  -  cost:  10106.869\n",
      "epoch :  235  -  cost:  14785.652\n",
      "epoch :  236  -  cost:  7829.689\n",
      "epoch :  237  -  cost:  17015.658\n",
      "epoch :  238  -  cost:  33772.07\n",
      "epoch :  239  -  cost:  19668.904\n",
      "epoch :  240  -  cost:  7235.337\n",
      "epoch :  241  -  cost:  17346.045\n",
      "epoch :  242  -  cost:  17456.223\n",
      "epoch :  243  -  cost:  7118.5586\n",
      "epoch :  244  -  cost:  19148.31\n",
      "epoch :  245  -  cost:  31779.049\n",
      "epoch :  246  -  cost:  12429.313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  247  -  cost:  12017.625\n",
      "epoch :  248  -  cost:  24474.277\n",
      "epoch :  249  -  cost:  6440.3677\n",
      "epoch :  250  -  cost:  40315.47\n",
      "epoch :  251  -  cost:  108502.695\n",
      "epoch :  252  -  cost:  21571.873\n",
      "epoch :  253  -  cost:  8487.442\n",
      "epoch :  254  -  cost:  11930.536\n",
      "epoch :  255  -  cost:  8565.227\n",
      "epoch :  256  -  cost:  6710.8037\n",
      "epoch :  257  -  cost:  11798.956\n",
      "epoch :  258  -  cost:  9851.589\n",
      "epoch :  259  -  cost:  13015.868\n",
      "epoch :  260  -  cost:  10121.784\n",
      "epoch :  261  -  cost:  12327.686\n",
      "epoch :  262  -  cost:  11061.796\n",
      "epoch :  263  -  cost:  10733.067\n",
      "epoch :  264  -  cost:  8222.76\n",
      "epoch :  265  -  cost:  16168.351\n",
      "epoch :  266  -  cost:  25027.908\n",
      "epoch :  267  -  cost:  4742.816\n",
      "epoch :  268  -  cost:  36003.062\n",
      "epoch :  269  -  cost:  80608.11\n",
      "epoch :  270  -  cost:  5173.123\n",
      "epoch :  271  -  cost:  118223.11\n",
      "epoch :  272  -  cost:  84195.42\n",
      "epoch :  273  -  cost:  6769.603\n",
      "epoch :  274  -  cost:  35566.457\n",
      "epoch :  275  -  cost:  7860.5522\n",
      "epoch :  276  -  cost:  55161.258\n",
      "epoch :  277  -  cost:  62539.418\n",
      "epoch :  278  -  cost:  4444.3184\n",
      "epoch :  279  -  cost:  37533.652\n",
      "epoch :  280  -  cost:  15711.722\n",
      "epoch :  281  -  cost:  32507.463\n",
      "epoch :  282  -  cost:  28030.35\n",
      "epoch :  283  -  cost:  8106.241\n",
      "epoch :  284  -  cost:  6843.6255\n",
      "epoch :  285  -  cost:  22026.91\n",
      "epoch :  286  -  cost:  10241.75\n",
      "epoch :  287  -  cost:  37973.75\n",
      "epoch :  288  -  cost:  19986.959\n",
      "epoch :  289  -  cost:  15583.036\n",
      "epoch :  290  -  cost:  12485.377\n",
      "epoch :  291  -  cost:  28355.02\n",
      "epoch :  292  -  cost:  9215.179\n",
      "epoch :  293  -  cost:  73231.336\n",
      "epoch :  294  -  cost:  107189.73\n",
      "epoch :  295  -  cost:  12480.49\n",
      "epoch :  296  -  cost:  43565.754\n",
      "epoch :  297  -  cost:  4333.5728\n",
      "epoch :  298  -  cost:  34019.344\n",
      "epoch :  299  -  cost:  3737.2554\n",
      "epoch :  300  -  cost:  58007.188\n",
      "epoch :  301  -  cost:  3827.9067\n",
      "epoch :  302  -  cost:  45651.25\n",
      "epoch :  303  -  cost:  17174.336\n",
      "epoch :  304  -  cost:  57879.316\n",
      "epoch :  305  -  cost:  66292.46\n",
      "epoch :  306  -  cost:  12666.542\n",
      "epoch :  307  -  cost:  14167.644\n",
      "epoch :  308  -  cost:  43848.113\n",
      "epoch :  309  -  cost:  42498.86\n",
      "epoch :  310  -  cost:  28262.871\n",
      "epoch :  311  -  cost:  15731.287\n",
      "epoch :  312  -  cost:  71666.61\n",
      "epoch :  313  -  cost:  65796.07\n",
      "epoch :  314  -  cost:  16841.912\n",
      "epoch :  315  -  cost:  16925.809\n",
      "epoch :  316  -  cost:  46392.09\n",
      "epoch :  317  -  cost:  11713.735\n",
      "epoch :  318  -  cost:  122958.61\n",
      "epoch :  319  -  cost:  56275.188\n",
      "epoch :  320  -  cost:  103970.98\n",
      "epoch :  321  -  cost:  59539.75\n",
      "epoch :  322  -  cost:  64166.1\n",
      "epoch :  323  -  cost:  64127.277\n",
      "epoch :  324  -  cost:  28937.514\n",
      "epoch :  325  -  cost:  13672.278\n",
      "epoch :  326  -  cost:  81375.13\n",
      "epoch :  327  -  cost:  14460.333\n",
      "epoch :  328  -  cost:  193843.02\n",
      "epoch :  329  -  cost:  13310.504\n",
      "epoch :  330  -  cost:  284632.34\n",
      "epoch :  331  -  cost:  7858.5654\n",
      "epoch :  332  -  cost:  107057.85\n",
      "epoch :  333  -  cost:  10339.363\n",
      "epoch :  334  -  cost:  21726.95\n",
      "epoch :  335  -  cost:  34929.473\n",
      "epoch :  336  -  cost:  4346.6406\n",
      "epoch :  337  -  cost:  66058.42\n",
      "epoch :  338  -  cost:  4916.7803\n",
      "epoch :  339  -  cost:  12038.601\n",
      "epoch :  340  -  cost:  37513.71\n",
      "epoch :  341  -  cost:  5079.881\n",
      "epoch :  342  -  cost:  73505.055\n",
      "epoch :  343  -  cost:  3178.1743\n",
      "epoch :  344  -  cost:  40941.574\n",
      "epoch :  345  -  cost:  4608.54\n",
      "epoch :  346  -  cost:  4216.7305\n",
      "epoch :  347  -  cost:  19237.76\n",
      "epoch :  348  -  cost:  5661.355\n",
      "epoch :  349  -  cost:  2858.5764\n",
      "epoch :  350  -  cost:  8042.6113\n",
      "epoch :  351  -  cost:  9648.921\n",
      "epoch :  352  -  cost:  3364.1165\n",
      "epoch :  353  -  cost:  2161.996\n",
      "epoch :  354  -  cost:  5171.689\n",
      "epoch :  355  -  cost:  5564.2676\n",
      "epoch :  356  -  cost:  2278.3953\n",
      "epoch :  357  -  cost:  1983.7316\n",
      "epoch :  358  -  cost:  2973.11\n",
      "epoch :  359  -  cost:  4043.386\n",
      "epoch :  360  -  cost:  3442.9712\n",
      "epoch :  361  -  cost:  2288.764\n",
      "epoch :  362  -  cost:  1691.1448\n",
      "epoch :  363  -  cost:  1956.8779\n",
      "epoch :  364  -  cost:  2840.299\n",
      "epoch :  365  -  cost:  2394.3691\n",
      "epoch :  366  -  cost:  1459.0463\n",
      "epoch :  367  -  cost:  1204.8656\n",
      "epoch :  368  -  cost:  1348.4891\n",
      "epoch :  369  -  cost:  1690.4354\n",
      "epoch :  370  -  cost:  1787.2352\n",
      "epoch :  371  -  cost:  1517.4374\n",
      "epoch :  372  -  cost:  1109.7576\n",
      "epoch :  373  -  cost:  957.06824\n",
      "epoch :  374  -  cost:  973.76825\n",
      "epoch :  375  -  cost:  1031.3677\n",
      "epoch :  376  -  cost:  1012.22\n",
      "epoch :  377  -  cost:  894.4974\n",
      "epoch :  378  -  cost:  759.52673\n",
      "epoch :  379  -  cost:  694.1182\n",
      "epoch :  380  -  cost:  681.69324\n",
      "epoch :  381  -  cost:  723.4447\n",
      "epoch :  382  -  cost:  719.3629\n",
      "epoch :  383  -  cost:  645.8342\n",
      "epoch :  384  -  cost:  536.569\n",
      "epoch :  385  -  cost:  469.2194\n",
      "epoch :  386  -  cost:  446.03653\n",
      "epoch :  387  -  cost:  439.68036\n",
      "epoch :  388  -  cost:  419.24908\n",
      "epoch :  389  -  cost:  381.33972\n",
      "epoch :  390  -  cost:  321.61798\n",
      "epoch :  391  -  cost:  248.3563\n",
      "epoch :  392  -  cost:  203.92682\n",
      "epoch :  393  -  cost:  195.32465\n",
      "epoch :  394  -  cost:  191.478\n",
      "epoch :  395  -  cost:  179.2321\n",
      "epoch :  396  -  cost:  160.17715\n",
      "epoch :  397  -  cost:  139.00146\n",
      "epoch :  398  -  cost:  114.403046\n",
      "epoch :  399  -  cost:  96.93491\n",
      "epoch :  400  -  cost:  79.93581\n",
      "epoch :  401  -  cost:  63.908154\n",
      "epoch :  402  -  cost:  55.6771\n",
      "epoch :  403  -  cost:  52.140347\n",
      "epoch :  404  -  cost:  47.791443\n",
      "epoch :  405  -  cost:  42.702145\n",
      "epoch :  406  -  cost:  36.93548\n",
      "epoch :  407  -  cost:  30.56311\n",
      "epoch :  408  -  cost:  23.622387\n",
      "epoch :  409  -  cost:  16.168133\n",
      "epoch :  410  -  cost:  8.265132\n",
      "epoch :  411  -  cost:  0.0\n",
      "epoch :  412  -  cost:  0.0\n",
      "epoch :  413  -  cost:  0.0\n",
      "epoch :  414  -  cost:  1.6085964\n",
      "epoch :  415  -  cost:  0.7103509\n",
      "epoch :  416  -  cost:  0.0\n",
      "epoch :  417  -  cost:  0.0\n",
      "epoch :  418  -  cost:  0.0\n",
      "epoch :  419  -  cost:  0.0\n",
      "epoch :  420  -  cost:  0.0\n",
      "epoch :  421  -  cost:  0.0\n",
      "epoch :  422  -  cost:  0.0\n",
      "epoch :  423  -  cost:  0.0\n",
      "epoch :  424  -  cost:  0.0\n",
      "epoch :  425  -  cost:  0.0\n",
      "epoch :  426  -  cost:  0.0\n",
      "epoch :  427  -  cost:  0.0\n",
      "epoch :  428  -  cost:  0.0\n",
      "epoch :  429  -  cost:  0.0\n",
      "epoch :  430  -  cost:  0.0\n",
      "epoch :  431  -  cost:  0.0\n",
      "epoch :  432  -  cost:  0.0\n",
      "epoch :  433  -  cost:  0.0\n",
      "epoch :  434  -  cost:  0.0\n",
      "epoch :  435  -  cost:  0.0\n",
      "epoch :  436  -  cost:  0.0\n",
      "epoch :  437  -  cost:  0.0\n",
      "epoch :  438  -  cost:  0.0\n",
      "epoch :  439  -  cost:  0.0\n",
      "epoch :  440  -  cost:  0.0\n",
      "epoch :  441  -  cost:  0.0\n",
      "epoch :  442  -  cost:  0.0\n",
      "epoch :  443  -  cost:  0.0\n",
      "epoch :  444  -  cost:  0.0\n",
      "epoch :  445  -  cost:  0.0\n",
      "epoch :  446  -  cost:  0.0\n",
      "epoch :  447  -  cost:  0.0\n",
      "epoch :  448  -  cost:  0.0\n",
      "epoch :  449  -  cost:  0.0\n",
      "epoch :  450  -  cost:  0.0\n",
      "epoch :  451  -  cost:  0.0\n",
      "epoch :  452  -  cost:  0.0\n",
      "epoch :  453  -  cost:  0.0\n",
      "epoch :  454  -  cost:  0.0\n",
      "epoch :  455  -  cost:  0.0\n",
      "epoch :  456  -  cost:  0.0\n",
      "epoch :  457  -  cost:  0.0\n",
      "epoch :  458  -  cost:  0.0\n",
      "epoch :  459  -  cost:  0.0\n",
      "epoch :  460  -  cost:  0.0\n",
      "epoch :  461  -  cost:  0.0\n",
      "epoch :  462  -  cost:  0.0\n",
      "epoch :  463  -  cost:  0.0\n",
      "epoch :  464  -  cost:  0.0\n",
      "epoch :  465  -  cost:  0.0\n",
      "epoch :  466  -  cost:  0.0\n",
      "epoch :  467  -  cost:  0.0\n",
      "epoch :  468  -  cost:  0.0\n",
      "epoch :  469  -  cost:  0.0\n",
      "epoch :  470  -  cost:  0.0\n",
      "epoch :  471  -  cost:  0.0\n",
      "epoch :  472  -  cost:  0.0\n",
      "epoch :  473  -  cost:  0.0\n",
      "epoch :  474  -  cost:  0.0\n",
      "epoch :  475  -  cost:  0.0\n",
      "epoch :  476  -  cost:  0.0\n",
      "epoch :  477  -  cost:  0.0\n",
      "epoch :  478  -  cost:  0.0\n",
      "epoch :  479  -  cost:  0.0\n",
      "epoch :  480  -  cost:  0.0\n",
      "epoch :  481  -  cost:  0.0\n",
      "epoch :  482  -  cost:  0.0\n",
      "epoch :  483  -  cost:  0.0\n",
      "epoch :  484  -  cost:  0.0\n",
      "epoch :  485  -  cost:  0.0\n",
      "epoch :  486  -  cost:  0.0\n",
      "epoch :  487  -  cost:  0.0\n",
      "epoch :  488  -  cost:  0.0\n",
      "epoch :  489  -  cost:  0.0\n",
      "epoch :  490  -  cost:  0.0\n",
      "epoch :  491  -  cost:  0.0\n",
      "epoch :  492  -  cost:  0.0\n",
      "epoch :  493  -  cost:  0.0\n",
      "epoch :  494  -  cost:  0.0\n",
      "epoch :  495  -  cost:  0.0\n",
      "epoch :  496  -  cost:  0.0\n",
      "epoch :  497  -  cost:  0.0\n",
      "epoch :  498  -  cost:  0.0\n",
      "epoch :  499  -  cost:  0.0\n"
     ]
    }
   ],
   "source": [
    "cost_history=[]\n",
    "n_epochs =500\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(init)\n",
    "train_y=train_y.todense()\n",
    "for i in range(n_epochs):\n",
    "    a, c = sess.run([optimizer, cost], feed_dict={x: train_x, y_: train_y})  \n",
    "    cost_history = np.append(cost_history,c)  \n",
    "    print('epoch : ', i, ' - ', 'cost: ', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5650acf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(range(0,500), cost_history[0:500])\n",
    "plt.ylabel('COST')\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylim([0, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f56cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.66\n"
     ]
    }
   ],
   "source": [
    "test_y=test_y.todense() \n",
    "correct_prediction = tf.equal(tf.argmax(model,1), tf.argmax(y_,1))   \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={x: test_x, y_:test_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619270a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr tf2.4 py3.8",
   "language": "python",
   "name": "cvpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
